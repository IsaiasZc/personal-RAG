{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.core.prompts import BasePromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/out/recipes_flat.json\"\n",
    "df = pd.read_json(file_path)\n",
    "llm_gpt = OpenAI(model=\"gpt-4o-mini\", temperature=0.5, max_tokens=100)\n",
    "# embed_gpt = OpenAIEmbedding(model='text-embedding-3-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///data/out/recipes.db\")\n",
    "\n",
    "sql_database = SQLDatabase(\n",
    "    engine=engine, include_tables=[\"recipes\"], sample_rows_in_table_info=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tune the model because the LLM can return aswers that are not related to the question. We can use a simple heuristic to filter out these answers. We can check if the answer contains any of the words in the question. If it does, we can discard the answer. This heuristic is not perfect, but it can help to improve the performance of the model. we can modify the model for the query search and the response too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_MODEL = \"\"\"\n",
    "'Given an input question, synthesize a response from the query results.\n",
    "\n",
    "If the question is about a recipe, provide the recipe details. If the answer is not in the database, respond with \"I don't have that information\". If the question is not about a recipe, respond with \"I just can help you with recipes\".\n",
    "\n",
    "\n",
    "Query: {query_str}\n",
    "SQL: {sql_query}\n",
    "SQL Response: {context_str}\n",
    "Response: '\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response_synthesis_prompt = PromptTemplate(\n",
    "    template=PROMPT_MODEL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"recipes\"],\n",
    "    llm=llm_gpt,\n",
    "    response_synthesis_prompt=response_synthesis_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['query_str', 'sql_query', 'context_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='\\n\\'Given an input question, synthesize a response from the query results.\\n\\nIf the question is about a recipe, provide the recipe details. If the answer is not in the database, respond with \"I don\\'t have that information\". If the question is not about a recipe, respond with \"I just can help you with recipes\".\\n\\n\\nQuery: {query_str}\\nSQL: {sql_query}\\nSQL Response: {context_str}\\nResponse: \\'\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.get_prompts()[\"response_synthesis_prompt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just can help you with recipes.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Quien es José Smith\"\n",
    "response = query_engine.query(query_str)\n",
    "response.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM recipes WHERE ingredients LIKE '%José Smith%'\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata[\"sql_query\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata[\"result\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
